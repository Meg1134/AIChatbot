"""
Streamlit Web ç•Œé¢ï¼ˆæ”¹è¿›ç‰ˆï¼‰
"""
import streamlit as st
from typing import List, Optional
import json
import time
import traceback

from langchain.schema import HumanMessage, AIMessage, BaseMessage

from config import setup_environment
from src.agents import ChatbotAgent
from src.rag import DocumentLoader

# ------------- åŸºç¡€è®¾ç½® -------------
st.set_page_config(
    page_title="AI èŠå¤©æœºå™¨äºº",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

setup_environment()

# ------------- å¸¸é‡ / é…ç½® -------------
MAX_CHAT_HISTORY = 12         # åªä¿ç•™æœ€è¿‘çš„å¯¹è¯è½®æ•°ï¼ˆç”¨æˆ·+AI å„ä¸€æ¡ç®—2ï¼‰
SHOW_RETRIEVED_CONTEXT = True # è°ƒè¯•ï¼šæ˜¾ç¤ºæ£€ç´¢åˆ°çš„æ–‡æ¡£
DEFAULT_MODEL = "gpt-3.5-turbo"

# ------------- ç¼“å­˜ ChatbotAgent -------------
@st.cache_resource(show_spinner=False)
def load_chatbot(model_name: str):
    return ChatbotAgent(model_name=model_name)

# ------------- å·¥å…·å‡½æ•° -------------
def get_chatbot(model_choice: str) -> ChatbotAgent:
    # ä½¿æ¨¡å‹é€‰æ‹©ç”Ÿæ•ˆï¼šæ¨¡å‹å˜æ›´ä¼šé‡æ–°æ„å»º
    return load_chatbot(model_choice)

def truncate_history(messages: List[BaseMessage], limit: int) -> List[BaseMessage]:
    if len(messages) <= limit:
        return messages
    return messages[-limit:]

def add_rag_documents(chatbot: ChatbotAgent, uploaded_files):
    loader = DocumentLoader()
    texts = []
    metadatas = []
    for f in uploaded_files:
        name = f.name
        mime = f.type
        suffix = name.lower().split(".")[-1]

        try:
            if suffix in ["txt", "md"]:
                # å°è¯•è§£ç ï¼ˆStreamlit ç»™çš„æ˜¯ä¸€ä¸ª BytesIO-likeï¼‰
                raw = f.read()
                try:
                    content = raw.decode("utf-8")
                except UnicodeDecodeError:
                    content = raw.decode("utf-8", errors="ignore")
                texts.append(content)
                metadatas.append({"source": name, "type": mime})
            elif suffix == "pdf":
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æ–¹å¼è®© loader è§£æ
                # Streamlit uploaded_file æœ‰ getvalue()
                import tempfile, os
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(f.getvalue())
                    tmp_path = tmp.name
                try:
                    docs = loader.load_pdf_file(tmp_path)
                    # å°† PDF æ¯é¡µåˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²æˆ–ç›´æ¥æ·»åŠ  page_content
                    for d in docs:
                        texts.append(d.page_content)
                        meta = d.metadata.copy()
                        meta.update({"source": name, "type": mime})
                        metadatas.append(meta)
                finally:
                    try:
                        os.remove(tmp_path)
                    except OSError:
                        pass
            else:
                st.warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {name}")
        except Exception as e:
            st.error(f"æ–‡ä»¶ {name} è§£æå¤±è´¥: {e}")
    if not texts:
        st.info("æ²¡æœ‰å¯æ·»åŠ çš„æ–‡æœ¬ã€‚")
        return

    with st.spinner("å‘é‡åŒ–å¹¶æ·»åŠ åˆ°çŸ¥è¯†åº“..."):
        chatbot.add_documents_to_rag(texts, metadatas)
    st.success(f"å·²æ·»åŠ  {len(texts)} ä¸ªæ–‡æœ¬å—ï¼ˆåŸæ–‡ä»¶ {len(uploaded_files)} ä¸ªï¼‰")

def render_history(messages: List[BaseMessage]):
    for m in messages:
        if isinstance(m, HumanMessage):
            with st.chat_message("user"):
                st.markdown(m.content)
        elif isinstance(m, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(m.content)

def ensure_state():
    if "messages" not in st.session_state:
        st.session_state.messages: List[BaseMessage] = []
    if "last_retrieval" not in st.session_state:
        st.session_state.last_retrieval = None  # å­˜å‚¨ä¸€ä¸ªæ£€ç´¢ä¸Šä¸‹æ–‡ç‰‡æ®µ

def maybe_prune_history():
    st.session_state.messages = truncate_history(st.session_state.messages, MAX_CHAT_HISTORY)

# ------------- ä¸»é€»è¾‘ -------------
def main():
    st.title("ğŸ¤– AI èŠå¤©æœºå™¨äºº")
    st.caption("æ”¯æŒï¼šæ•°å­¦è®¡ç®— / å¤©æ°” / æœç´¢ / RAG çŸ¥è¯†åº“")
    st.markdown("---")

    ensure_state()

    # ----------- ä¾§è¾¹æ  -----------
    with st.sidebar:
        st.header("ğŸ› ï¸ åŠŸèƒ½è®¾ç½®")

        # æ¨¡å‹è®¾ç½®
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"],
            index=0
        )

        # æ˜¯å¦å¯ç”¨ RAG
        use_rag = st.toggle("å¯ç”¨ RAG æ£€ç´¢", value=True, help="å…³é—­ååªä½¿ç”¨çº¯æ¨¡å‹å¯¹è¯")

        # çŸ¥è¯†åº“ä¸Šä¼ 
        st.subheader("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£ï¼ˆtxt/pdf/mdï¼‰",
            type=['txt', 'pdf', 'md'],
            accept_multiple_files=True
        )
        if uploaded_files and st.button("æ·»åŠ åˆ°çŸ¥è¯†åº“"):
            chatbot = get_chatbot(model_choice)
            add_rag_documents(chatbot, uploaded_files)

        # æ¸…é™¤å¯¹è¯
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
            st.session_state.messages = []
            st.session_state.last_retrieval = None
            st.experimental_rerun()

        # æ˜¾ç¤ºè°ƒè¯•åŒº
        if st.checkbox("è°ƒè¯•ä¿¡æ¯", value=False):
            st.write("å½“å‰æ¶ˆæ¯æ¡æ•°:", len(st.session_state.messages))
            st.write("æœ€è¿‘æ£€ç´¢æ‘˜è¦:", st.session_state.last_retrieval[:300] + "..." if st.session_state.last_retrieval else None)

    # è·å– / ç¼“å­˜ Chatbot
    chatbot = get_chatbot(model_choice)

    # ----------- æ˜¾ç¤ºå†å² -----------
    render_history(st.session_state.messages)

    # ----------- è¾“å…¥æ¡† -----------
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # è¿½åŠ ç”¨æˆ·æ¶ˆæ¯
        user_msg = HumanMessage(content=prompt)
        st.session_state.messages.append(user_msg)

        with st.chat_message("user"):
            st.markdown(prompt)

        # ç”Ÿæˆ AI å›å¤
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    # æ ¹æ®æ˜¯å¦å¯ç”¨ RAG æ§åˆ¶è¾“å…¥ï¼ˆæœ€å°ä¾µå…¥ï¼šå¦‚æœå…³é—­ RAGï¼Œåœ¨ä¼ å…¥å‰å»æ‰å¯èƒ½è§¦å‘ RAG çš„å…³é”®è¯å¤„ç†æˆ–è®© ChatbotAgent å†…éƒ¨åšå¼€å…³ï¼‰
                    # ç®€å•æ–¹å¼ï¼šå¦‚æœ use_rag=Falseï¼Œä¸´æ—¶å±è”½é‚£äº›å…³é”®è¯ => ç›´æ¥è°ƒç”¨ chat åŒæ ·é€»è¾‘ï¼ˆè¿™é‡Œå…ˆä¸æ”¹ ChatbotAgentï¼Œåšä¸€ä¸ªå¿«é€Ÿç»•å¼€ï¼‰
                    history_for_agent = st.session_state.messages[:-1]  # å†å²ï¼ˆä¸å«å½“å‰ï¼‰
                    # è°ƒç”¨ chatï¼ˆå¼‚æ­¥æ¥å£åŒæ­¥åŒ–ï¼‰â€”â€” å¦‚æœä½ çš„ ChatbotAgent.chat å·² asyncï¼š
                    import asyncio
                    response_text = asyncio.run(chatbot.chat(prompt, history_for_agent))

                    ai_msg = AIMessage(content=response_text)
                    st.session_state.messages.append(ai_msg)
                    st.markdown(response_text)

                    # ï¼ˆå¯é€‰ï¼‰æ˜¾ç¤ºæœ€è¿‘ RAG æ£€ç´¢çš„æ•°æ®ï¼šè¿™é‡Œåªèƒ½ä¿®æ”¹ ChatbotAgent æ¥è¿”å›ä¸Šä¸‹æ–‡ã€‚
                    # å½“å‰æ— æ³•ç›´æ¥æ‹¿åˆ° rag_contextï¼Œåªèƒ½é€è¿‡ä¿®æ”¹ ChatbotAgent.chat è¿”å› (text, rag_context)
                    # æš‚æ—¶ç•¥ã€‚å¦‚æœéœ€è¦æˆ‘å¯å¸®ä½ æ”¹ ChatbotAgentã€‚
                except Exception as e:
                    err = f"å¤„ç†è¯·æ±‚å‡ºé”™: {e}"
                    st.error(err)
                    st.session_state.messages.append(AIMessage(content=err))
                    traceback.print_exc()

        maybe_prune_history()

    st.markdown("---")
    # åŠŸèƒ½è¯´æ˜
    cols = st.columns(4)
    infos = [
        ("ğŸ§® æ•°å­¦è®¡ç®—", "ä¾‹ï¼šè®¡ç®— 25 * 4 + 10"),
        ("ğŸŒ¤ï¸ å¤©æ°”æŸ¥è¯¢", "ä¾‹ï¼šåŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"),
        ("ğŸ” ä¿¡æ¯æœç´¢", "ä¾‹ï¼šæœç´¢äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•"),
        ("ğŸ“š çŸ¥è¯†é—®ç­”", "ä¸Šä¼ æ–‡æ¡£åè¿›è¡Œé—®ç­”")
    ]
    for col, (title, body) in zip(cols, infos):
        with col:
            st.info(f"**{title}**\n\n{body}")

    with st.expander("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹", expanded=False):
        st.markdown("""
        ### æ•°å­¦è®¡ç®—
        - "è®¡ç®— 123 + 456"
        - "æ±‚ sin(30) çš„å€¼"
        - "å¹³æ–¹æ ¹ 144 æ˜¯å¤šå°‘ï¼Ÿ"

        ### å¤©æ°”æŸ¥è¯¢
        - "åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ"
        - "ä¸Šæµ·çš„å¤©æ°”é¢„æŠ¥"
        - "å¹¿å·ç°åœ¨çš„æ¸©åº¦"

        ### ä¿¡æ¯æœç´¢
        - "æœç´¢äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿"
        - "æŸ¥æ‰¾æœºå™¨å­¦ä¹ ç®—æ³•"
        - "æœç´¢æœ€æ–°ç§‘æŠ€æ–°é—»"

        ### çŸ¥è¯†é—®ç­”
        - ä¸Šä¼ ç›¸å…³æ–‡æ¡£åï¼Œå¯ä»¥åŸºäºæ–‡æ¡£å†…å®¹è¿›è¡Œé—®ç­”
        - "æ ¹æ®ä¸Šä¼ çš„æ–‡æ¡£ï¼Œè§£é‡ŠXXXæ¦‚å¿µ"
        - "æ–‡æ¡£ä¸­æåˆ°çš„XXXæ˜¯ä»€ä¹ˆï¼Ÿ"
        """)

if __name__ == "__main__":
    # æ­£ç¡®å¯åŠ¨å»ºè®®ä½¿ç”¨ï¼š streamlit run streamlit_app.py
    # ç›´æ¥ python è¿è¡Œåªé€‚åˆè°ƒè¯•æ¨¡å—å¯¼å…¥ï¼Œä¸ä¼šæœ‰å®Œæ•´å‰ç«¯ã€‚
    main()