"""
Streamlit Web ç•Œé¢
"""
import streamlit as st
import asyncio
from typing import List
from langchain.schema import HumanMessage, AIMessage

from config import setup_environment
from src.agents import ChatbotAgent
from src.rag import DocumentLoader


# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI èŠå¤©æœºå™¨äºº",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®ç¯å¢ƒå˜é‡
setup_environment()


@st.cache_resource
def load_chatbot():
    """åŠ è½½èŠå¤©æœºå™¨äººï¼ˆç¼“å­˜ï¼‰"""
    return ChatbotAgent()


def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¤– AI èŠå¤©æœºå™¨äºº")
    st.markdown("---")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ› ï¸ åŠŸèƒ½è®¾ç½®")
        
        # RAG æ–‡æ¡£ä¸Šä¼ 
        st.subheader("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“",
            type=['txt', 'pdf', 'md'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            if st.button("æ·»åŠ åˆ°çŸ¥è¯†åº“"):
                chatbot = load_chatbot()
                document_loader = DocumentLoader()
                
                texts = []
                metadatas = []
                
                for uploaded_file in uploaded_files:
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    if uploaded_file.type == "text/plain":
                        content = str(uploaded_file.read(), "utf-8")
                    else:
                        content = str(uploaded_file.read(), "utf-8")
                    
                    texts.append(content)
                    metadatas.append({
                        "source": uploaded_file.name,
                        "type": uploaded_file.type
                    })
                
                # æ·»åŠ åˆ° RAG ç³»ç»Ÿ
                chatbot.add_documents_to_rag(texts, metadatas)
                st.success(f"å·²æ·»åŠ  {len(uploaded_files)} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼")
        
        # æ¨¡å‹è®¾ç½®
        st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview"],
            index=0
        )
        
        # æ¸…é™¤å¯¹è¯å†å²
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
            if "messages" in st.session_state:
                del st.session_state.messages
            if "chatbot" in st.session_state:
                del st.session_state.chatbot
            st.rerun()
    
    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.messages:
            if isinstance(message, HumanMessage):
                with st.chat_message("user"):
                    st.markdown(message.content)
            elif isinstance(message, AIMessage):
                with st.chat_message("assistant"):
                    st.markdown(message.content)
    
    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        user_message = HumanMessage(content=prompt)
        st.session_state.messages.append(user_message)
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ç”Ÿæˆ AI å›å¤
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    chatbot = load_chatbot()
                    
                    # å¼‚æ­¥è°ƒç”¨èŠå¤©åŠŸèƒ½
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    response = loop.run_until_complete(
                        chatbot.chat(prompt, st.session_state.messages[:-1])
                    )
                    loop.close()
                    
                    # æ˜¾ç¤ºå›å¤
                    st.markdown(response)
                    
                    # æ·»åŠ  AI å›å¤åˆ°å†å²
                    ai_message = AIMessage(content=response)
                    st.session_state.messages.append(ai_message)
                    
                except Exception as e:
                    error_message = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
                    st.error(error_message)
                    
                    # æ·»åŠ é”™è¯¯æ¶ˆæ¯åˆ°å†å²
                    ai_message = AIMessage(content=error_message)
                    st.session_state.messages.append(ai_message)
    
    # åŠŸèƒ½å±•ç¤º
    st.markdown("---")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.info("ğŸ§® **æ•°å­¦è®¡ç®—**\n\nä¾‹ï¼šè®¡ç®— 25 * 4 + 10")
    
    with col2:
        st.info("ğŸŒ¤ï¸ **å¤©æ°”æŸ¥è¯¢**\n\nä¾‹ï¼šåŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
    
    with col3:
        st.info("ğŸ” **ä¿¡æ¯æœç´¢**\n\nä¾‹ï¼šæœç´¢äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•")
    
    with col4:
        st.info("ğŸ“š **çŸ¥è¯†é—®ç­”**\n\nåŸºäºä¸Šä¼ çš„æ–‡æ¡£å›ç­”é—®é¢˜")
    
    # ä½¿ç”¨ç¤ºä¾‹
    with st.expander("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹", expanded=False):
        st.markdown("""
        ### æ•°å­¦è®¡ç®—
        - "è®¡ç®— 123 + 456"
        - "æ±‚ sin(30) çš„å€¼"
        - "å¹³æ–¹æ ¹ 144 æ˜¯å¤šå°‘ï¼Ÿ"
        
        ### å¤©æ°”æŸ¥è¯¢
        - "åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ"
        - "ä¸Šæµ·çš„å¤©æ°”é¢„æŠ¥"
        - "å¹¿å·ç°åœ¨çš„æ¸©åº¦"
        
        ### ä¿¡æ¯æœç´¢
        - "æœç´¢äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿"
        - "æŸ¥æ‰¾æœºå™¨å­¦ä¹ ç®—æ³•"
        - "æœç´¢æœ€æ–°ç§‘æŠ€æ–°é—»"
        
        ### çŸ¥è¯†é—®ç­”
        - ä¸Šä¼ ç›¸å…³æ–‡æ¡£åï¼Œå¯ä»¥åŸºäºæ–‡æ¡£å†…å®¹è¿›è¡Œé—®ç­”
        - "æ ¹æ®ä¸Šä¼ çš„æ–‡æ¡£ï¼Œè§£é‡ŠXXXæ¦‚å¿µ"
        - "æ–‡æ¡£ä¸­æåˆ°çš„XXXæ˜¯ä»€ä¹ˆï¼Ÿ"
        """)


if __name__ == "__main__":
    main()
